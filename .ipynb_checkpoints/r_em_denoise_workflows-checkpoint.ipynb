{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd5196d-6560-48d6-8a0b-c0571663be9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Denoise/Restore Electron-Microscopy Images using the Deep-Learning Model by Lobato et al.\n",
    "\n",
    "This notebook contains ideas for denoising workflows using the model and guidelines from the official repository (https://github.com/Ivanlh20/r_em).  \n",
    "It shows how to use `tifffile` to load TIFF images, denoise them and save them back to TIFF.  \n",
    "Many electron-microscopy file formats can be read in with `RosettaSciIO` (https://hyperspy.org/rosettasciio/), an I/O sub-package from `HyperSpy`. The end of the notebook shows examples for the latter.\n",
    "\n",
    "**Please cite their work in your publications if it helps your research:**\n",
    "```bibtex\n",
    "@article{Lobato2023,\n",
    "   author = {I. Lobato and T. Friedrich and S. Van Aert},\n",
    "   month = {3},\n",
    "   title = {Deep convolutional neural networks to restore single-shot electron microscopy images},\n",
    "   url = {https://arxiv.org/abs/2303.17025v1},\n",
    "   year = {2023},\n",
    "}\n",
    "```\n",
    "\n",
    "This notebook was run with a single desktop GPU (RTX 2060 with 6GB VRAM).  \n",
    "\n",
    "To get CUDA running on a Nvidia GPU, follow the installation instructions in the official [repository](https://github.com/Ivanlh20/r_em).  \n",
    "I ran it with `CUDA 11.2` ([link](https://developer.nvidia.com/cuda-toolkit-archive)), `cuDNN 8.1` ([link](https://developer.nvidia.com/rdp/cudnn-archive), requires Nvidia developer account) required by the `tensorflow-2.10.0` [build](https://www.tensorflow.org/install/source#gpu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c1edd90-4928-473f-b01f-3a73a8184f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Sun_Feb_14_22:08:44_Pacific_Standard_Time_2021\n",
      "Cuda compilation tools, release 11.2, V11.2.152\n",
      "Build cuda_11.2.r11.2/compiler.29618528_0\n"
     ]
    }
   ],
   "source": [
    "# Optional, to check CUDA version\n",
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa91a02f-4495-427d-9d55-0e07f177b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "122e5529-d5d4-4c26-a38e-ad2041fa9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tk_r_em import load_network\n",
    "\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2492b3a6-8317-4663-8b68-c1069f347fda",
   "metadata": {},
   "source": [
    "#### Denoising of...\n",
    "  1. [Single image](#1-Single-image)\n",
    "  2. [Single *large* image](#2-Single-large-image-that-does-not-fit-into-GPU-memory) (that does not fit into GPU memory)\n",
    "  3. [Image Stack](#3-Image-Stack) (e.g., time or focus series)\n",
    "  4. [Batch Denoising](#4-Batch-Denoising)\n",
    "  5. [TFS/FEI SEM TIFF Batch Denoising](#5-TFS/FEI-TIFF-Batch-Denoising)\n",
    "  6. [Electron-Microscopy Formats (ser/dm3), single image](#6-Electron-Microscopy-Formats-(ser/dm3),-single-image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbcaf14-b800-4857-b72a-0adefe71091a",
   "metadata": {},
   "source": [
    "## 1 Single image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a998ba9c-e6a8-4536-9f50-09d16c530800",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load an image\n",
    "The image values must be present as a two-dimensional numpy array for denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaccef30-4834-4f56-837a-2bf08bc50f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image file\n",
    "image_file = r'examples/single_image/Tecnai_Osiris_SrTiO3.tif'\n",
    "\n",
    "# Choose denoising model\n",
    "net_name = 'sfr_hrstem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9fef4f-d38a-4702-8167-970a4124776e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:\t(512, 512)\n",
      "Data type:\tuint16\n"
     ]
    }
   ],
   "source": [
    "image = tifffile.imread(image_file)\n",
    "print(f'Image shape:\\t{image.shape}')\n",
    "print(f'Data type:\\t{image.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e457f13-feb0-4499-94e9-4676b2e64e6a",
   "metadata": {},
   "source": [
    "We give the 2D image the correct shape for the network (z, y, x, 1) by adding two dimensions. For a single image we use $z = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40269a54-4f86-4f9b-bd05-cd6a0e4b6bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:\t(1, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "image = np.expand_dims(image, axis=(0, -1))\n",
    "print(f'Image shape:\\t{image.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23240057-68b5-46b3-89cb-f326e4b8fe6c",
   "metadata": {},
   "source": [
    "#### Denoise the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592c3b89-25bb-4ca6-814c-f0f989e2d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_em_nn = load_network(net_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f4ffa0-79a8-4da8-8197-f5db11013df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = r_em_nn.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008930aa-d5c7-4f76-8065-d5766f6f3c8d",
   "metadata": {},
   "source": [
    "#### Plot the results\n",
    "Tip: If using an interactive matplotlib backend such as `qt` or `widget`, use the zoom feature to compare the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82fa6634-59ea-4c6c-9398-210e18588dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12,6.5), sharex=True, sharey=True)\n",
    "\n",
    "cmap = 'gray' # 'turbo'\n",
    "\n",
    "axs[0].imshow(image[0,:,:,0], cmap=cmap)\n",
    "axs[0].set_title('Original')\n",
    "axs[1].imshow(denoised[0,:,:,0], cmap=cmap)\n",
    "axs[1].set_title(f'Denoised ({net_name})')\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e912837-7ef3-4117-a369-7b75befc8c25",
   "metadata": {},
   "source": [
    "#### Save results to TIFF\n",
    "Can then be loaded into other software such as ImageJ/Fiji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6debf6fd-7ccd-47a7-95e8-3b34eede345f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    }
   ],
   "source": [
    "# This is a cell to read out the pixel size and unit of ImageJ TIFF files, may be changed depending on image metadata\n",
    "with tifffile.TiffFile(image_file) as tiff:\n",
    "    tags = tiff.pages[0].tags\n",
    "    pixelsize = tags['XResolution'].value[1]/tags['XResolution'].value[0]\n",
    "    #tags[\"ResolutionUnit\"].value\n",
    "    if tiff.is_imagej:\n",
    "        unit = tiff.imagej_metadata[\"unit\"]\n",
    "    else:\n",
    "        unit = 'px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3f3fae-408d-4f44-b9cb-cf9dcefd7039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pixel size and unit\n",
    "pixelsize = pixelsize\n",
    "unit = unit\n",
    "\n",
    "# Save as TIFF image (32-bit)\n",
    "tifffile.imwrite(image_file.rsplit('.', maxsplit=1)[0]+f'-denoise-{net_name}.tif', denoised, imagej=True, \n",
    "        resolution=(1./pixelsize, 1./pixelsize), \n",
    "        metadata={'unit': unit})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb66605-4314-4fd4-80d1-2acb812a16e2",
   "metadata": {},
   "source": [
    "## 2 Single *large* image that does not fit into GPU memory\n",
    "Use smaller batches to fit in GPU memory.  \n",
    "From tests on my 6GB RTX 2060: 1024x1024 16-bit images work, 2048x2048 is too large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72aefc35-3f90-45f2-89cc-7a1552963a92",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load an image\n",
    "The image values must be present as a two-dimensional numpy array for denoising.  \n",
    "This functionality was added in version 1.0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b9d0b28-410a-4518-83f2-902be38e1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image file\n",
    "image_file = r'examples/single_large_image/HAADF_GdBCO_on_MgO.tif'\n",
    "\n",
    "# Choose denoising model\n",
    "net_name = 'sfr_hrstem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee5464ba-ce6c-4e58-bb8b-73bae031abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:\t(2048, 2048)\n",
      "Data type:\tuint16\n"
     ]
    }
   ],
   "source": [
    "image = tifffile.imread(image_file)\n",
    "original_dims = image.shape\n",
    "print(f'Image shape:\\t{image.shape}')\n",
    "print(f'Data type:\\t{image.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fabd9ba-6e3d-4ecb-8b0e-4571b022f833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:\t(1, 2048, 2048, 1)\n"
     ]
    }
   ],
   "source": [
    "image = np.expand_dims(image, axis=(0, -1))\n",
    "print(f'Image shape:\\t{image.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35343c9-2d82-495c-9eea-ffc8a59c07b9",
   "metadata": {},
   "source": [
    "#### Denoise the image in patches that fit into GPU memory\n",
    "An overlap is used to remove unwanted artefacts at the patch edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cb58c04-a8f5-4e5c-9771-f06fc77e3244",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_em_nn = load_network(net_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5a58b46-1ed4-47e4-87fd-95bf39bd55b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "denoised = r_em_nn.predict_patch_based(image, patch_size=512, stride=256, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac704f-e7a0-4601-8d07-d2a3ed73a7ea",
   "metadata": {},
   "source": [
    "#### Plot the results\n",
    "Tip: If using an interactive matplotlib backend such as `qt` or `widget`, use the zoom feature to compare the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec375733-aa5d-4d20-adde-f2c022ee1638",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12,6.5), sharex=True, sharey=True)\n",
    "\n",
    "cmap = 'gray' # 'turbo'\n",
    "\n",
    "axs[0].imshow(image[0,:,:,0], cmap=cmap)\n",
    "axs[0].set_title('Original')\n",
    "axs[1].imshow(denoised, cmap=cmap)\n",
    "axs[1].set_title(f'Denoised ({net_name})')\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f065eab-80c2-4fa8-8231-35aa3f1cad77",
   "metadata": {},
   "source": [
    "#### Save results to TIFF\n",
    "Can then be loaded into other software such as ImageJ/Fiji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0480c19-05f8-4802-b3cf-468f7bfde395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a cell to read out the pixel size and unit of ImageJ TIFF files, may be changed depending on image metadata\n",
    "with tifffile.TiffFile(image_file) as tiff:\n",
    "    tags = tiff.pages[0].tags\n",
    "    pixelsize = tags['XResolution'].value[1]/tags['XResolution'].value[0]\n",
    "    #tags[\"ResolutionUnit\"].value\n",
    "    if tiff.is_imagej:\n",
    "        unit = tiff.imagej_metadata[\"unit\"]\n",
    "    else:\n",
    "        unit = 'px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "722c5f14-46b9-41b0-abae-d0dbaaa9c7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pixel size and unit\n",
    "pixelsize = pixelsize\n",
    "unit = unit\n",
    "\n",
    "# Save as TIFF image (32-bit)\n",
    "tifffile.imwrite(image_file.rsplit('.', maxsplit=1)[0]+f'-denoise-{net_name}.tif', denoised, imagej=True, \n",
    "        resolution=(1./pixelsize, 1./pixelsize), \n",
    "        metadata={'unit': unit})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aab430-b088-4021-b707-762ad64fdbc7",
   "metadata": {},
   "source": [
    "## 3 Image Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f3b63a-421c-4134-9d43-cd1296becca5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load an image stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "392dd866-6a7a-4b47-9c26-0ba73aac378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image file\n",
    "image_file = r'examples/stack/BaFe2As2_Stack.tif'\n",
    "\n",
    "# Choose denoising model\n",
    "net_name = 'sfr_hrstem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62b7ae48-9ea6-4a0a-8b19-09b499ff2b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:\t(32, 512, 512)\n",
      "Data type:\tuint8\n"
     ]
    }
   ],
   "source": [
    "image = tifffile.imread(image_file)\n",
    "print(f'Image shape:\\t{image.shape}')\n",
    "print(f'Data type:\\t{image.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eeff3d-ef40-4197-b208-638a437e0698",
   "metadata": {},
   "source": [
    "We give the 3D image stack the correct shape for the network by adding a dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46d58b24-55b9-4898-b5d0-4f56b3c01f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:\t(32, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "image = np.expand_dims(image, axis=-1)\n",
    "# #images, y, x, 1\n",
    "print(f'Image shape:\\t{image.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cdb33f-18a7-4656-902c-05baabaf1211",
   "metadata": {},
   "source": [
    "#### Denoise the image stack\n",
    "Batch size can be varied based on GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ef8f58a-c3a1-4a02-b710-314752f15430",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_em_nn = load_network(net_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "446fd7d4-a7b2-4c93-a360-beb44bc0e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = r_em_nn.predict(image, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b053dcd2-809d-4e5f-8cc7-ae5e89684f5f",
   "metadata": {},
   "source": [
    "#### Plot the results\n",
    "Tip: If using an interactive matplotlib backend such as `qt` or `widget`, use the zoom feature to compare the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88384a95-d4c7-4c5d-bd3e-d22b5dd2d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12,6.5), sharex=True, sharey=True)\n",
    "\n",
    "cmap = 'gray' # 'turbo'\n",
    "image_index = 7 \n",
    "\n",
    "axs[0].imshow(image[image_index,:,:,0], cmap=cmap)\n",
    "axs[0].set_title('Original')\n",
    "axs[1].imshow(denoised[image_index,:,:,0], cmap=cmap)\n",
    "axs[1].set_title(f'Denoised ({net_name})')\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636d3b99-b65e-4b24-9cbb-2203b9c55e5c",
   "metadata": {},
   "source": [
    "#### Save results to TIFF\n",
    "Can then be loaded into other software such as ImageJ/Fiji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe3b3a38-079b-42b5-8755-cbe931217d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a cell to read out the pixel size and unit of ImageJ TIFF files, may be changed depending on image metadata\n",
    "with tifffile.TiffFile(image_file) as tiff:\n",
    "    tags = tiff.pages[0].tags\n",
    "    pixelsize = tags['XResolution'].value[1]/tags['XResolution'].value[0]\n",
    "    #tags[\"ResolutionUnit\"].value\n",
    "    if tiff.is_imagej:\n",
    "        unit = tiff.imagej_metadata[\"unit\"]\n",
    "    else:\n",
    "        unit = 'px'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b37abec-73db-47c4-b439-e597a3c37957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 32, 1, 512, 512, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape stack to have images as z slices\n",
    "# imagej=True has order: TZCYXS, see docstring of tifffile.TiffWriter()\n",
    "denoised_imagej = np.expand_dims(denoised, axis=(2,0))\n",
    "denoised_imagej.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "275488cd-958a-4653-8800-bca11527e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pixel size and unit\n",
    "pixelsize = pixelsize\n",
    "unit = unit\n",
    "\n",
    "# Save as TIFF image (32-bit)\n",
    "tifffile.imwrite(image_file.rsplit('.', maxsplit=1)[0]+f'-denoise-{net_name}.tif', denoised_imagej, imagej=True, \n",
    "        resolution=(1./pixelsize, 1./pixelsize), \n",
    "        metadata={'unit': unit})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43aa41-b6c3-4137-ac44-4b2870641321",
   "metadata": {},
   "source": [
    "## 4 Batch Denoising\n",
    "Batch processing of images. To use different models for SEM/STEM/TEM images, we prepare the following folder structure:\n",
    "```\n",
    "denoise_dir\n",
    "    |---sfr_hrstem\n",
    "        |---hrstem-image-01.tif\n",
    "        |---hrstem-image-02.tif\n",
    "    |---sfr_hrsem\n",
    "        |---some-sem-image.tif\n",
    "        |---another-sem-image.tif\n",
    "    |---...OTHER MODELS...\n",
    "        |---...\n",
    "```\n",
    "Copy your (TIFF) images in the respective folder with the model name.  \n",
    "We load the model based on the subfolder name and then denoise each image in the subfolder with the corresponding model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa75c0-ed3b-4b5b-97b3-fc3a8f066b43",
   "metadata": {},
   "source": [
    "#### User input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a75398b8-312c-43a0-b506-81cedf7d7791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the denoising directory\n",
    "denoise_dir = r'examples/batch_denoise'\n",
    "\n",
    "# Specify maximum image size which fits into your GPU memory\n",
    "# Use patch-based method if x or y dimension is larger than max_size_gpu\n",
    "max_size_gpu = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e520d4-50fa-4cb0-8e99-6ddc181b2f6e",
   "metadata": {},
   "source": [
    "Count number of images (here only TIFF files are detected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b507ffcd-f0aa-41c0-883e-a8f1439e9292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected models: 2\n",
      "Number of detected images: 3\n"
     ]
    }
   ],
   "source": [
    "valid_models = ['sfr_hrstem', 'sfr_lrstem', 'sfr_hrsem', 'sfr_lrsem', 'sfr_hrtem', 'sfr_lrtem']\n",
    "N = 0\n",
    "N_models = 0\n",
    "for m in next(os.walk(denoise_dir))[1]:\n",
    "    if m in valid_models:\n",
    "        N_models += 1\n",
    "        files = glob.glob(denoise_dir+'\\\\'+m+'\\\\*.tif')\n",
    "        N += len(files)\n",
    "print(f'Number of detected models: {N_models}')\n",
    "print(f'Number of detected images: {N}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df863f-ec7e-4a6b-b384-357f5100fd57",
   "metadata": {},
   "source": [
    "Proceed with batch denoising:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c385b122-9826-411a-abb7-fc1b81d76e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising of 3 images.\n",
      "########################\n",
      "Model: sfr_hrsem\n",
      "Loading network...\n",
      "Creation of the directory examples/batch_denoise\\sfr_hrsem\\output failed. Probably already present.\n",
      "Denoising images...\n",
      "Image 1/3\n",
      "########################\n",
      "Model: sfr_hrstem\n",
      "Loading network...\n",
      "Creation of the directory examples/batch_denoise\\sfr_hrstem\\output failed. Probably already present.\n",
      "Denoising images...\n",
      "Image 2/3\n",
      "Patch-based denoise...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########################\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "\n",
    "print(f'Denoising of {N} images.')\n",
    "print('########################')\n",
    "for m in next(os.walk(denoise_dir))[1]:\n",
    "    if m in valid_models:\n",
    "        # Load model\n",
    "        print(f'Model: {m}')\n",
    "        print('Loading network...')\n",
    "        r_em_nn = load_network(m)\n",
    "        \n",
    "        # Create folder for output files\n",
    "        outputpath = denoise_dir + '\\\\' + m + '\\\\output'\n",
    "        try: os.mkdir(outputpath)\n",
    "        except OSError: print(f'Creation of the directory {outputpath} failed. Probably already present.')\n",
    "        else: print(f'Successfully created the directory {outputpath}')\n",
    "        \n",
    "        # Detect and prepare image files\n",
    "        files = glob.glob(denoise_dir+'\\\\'+m+'\\\\*.tif')\n",
    "        print('Denoising images...')\n",
    "        for f in files:\n",
    "            print(f'Image {counter}/{N}')\n",
    "            image = tifffile.imread(f)\n",
    "            nx, ny = image.shape\n",
    "            image = np.expand_dims(image, axis=(0, -1))\n",
    "            \n",
    "            # Denoise\n",
    "            if nx > max_size_gpu or ny > max_size_gpu:\n",
    "                print('Patch-based denoise...')\n",
    "                denoised = r_em_nn.predict_patch_based(image, patch_size=int(max_size_gpu/2), stride=int(max_size_gpu/4), batch_size=2)\n",
    "            else:\n",
    "                denoised = r_em_nn.predict(image)\n",
    "            \n",
    "            # This is a cell to read out the pixel size and unit of ImageJ TIFF files, may be changed depending on image metadata\n",
    "            with tifffile.TiffFile(f) as tiff:\n",
    "                tags = tiff.pages[0].tags\n",
    "                pixelsize = tags['XResolution'].value[1]/tags['XResolution'].value[0]\n",
    "                #tags[\"ResolutionUnit\"].value\n",
    "                if tiff.is_imagej:\n",
    "                    unit = tiff.imagej_metadata[\"unit\"]\n",
    "                else:\n",
    "                    unit = 'px'\n",
    "            \n",
    "            # Define pixel size and unit\n",
    "            pixelsize = pixelsize\n",
    "            unit = unit\n",
    "\n",
    "            # Save as TIFF image (32-bit)\n",
    "            tifffile.imwrite(outputpath + '\\\\' + f.rsplit('.', maxsplit=1)[0].split('\\\\')[-1] + f'-denoise-{m}.tif', denoised, imagej=True, \n",
    "                    resolution=(1./pixelsize, 1./pixelsize), \n",
    "                    metadata={'unit': unit})\n",
    "            counter += 1\n",
    "            \n",
    "        print('########################')\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e869ac63-aed6-4e40-8203-e76c0cf2efc5",
   "metadata": {},
   "source": [
    "## 5 TFS/FEI TIFF Batch Denoising\n",
    "Batch processing of TFS/FEI SEM images. It removes the data bar and sets the physical pixel size based on the TIFF metadata.  \n",
    "To use different models for SEM/STEM-in-SEM images, we prepare the following folder structure:\n",
    "```\n",
    "denoise_dir\n",
    "    |---sfr_lrsem\n",
    "        |---sem-image-01.tif\n",
    "        |---sem-image-02.tif\n",
    "    |---sfr_hrsem\n",
    "        |---hrsem-image-01.tif\n",
    "        |---hrsem-image-02.tif\n",
    "    |---...OTHER MODELS...\n",
    "        |---...\n",
    "```\n",
    "Copy your TFS/FEI TIFF images in the respective folder with the model name.  \n",
    "We load the model based on the subfolder name and then denoise each image in the subfolder with the corresponding model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d52c9af-7b64-4e0c-aec6-b16d8967cb29",
   "metadata": {},
   "source": [
    "#### User input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "155f4789-14c8-442e-a3cf-c3d9bb1572ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the denoising directory\n",
    "denoise_dir = r'examples/tfs_fei_TIFF_denoise'\n",
    "\n",
    "# Specify maximum image size which fits into your GPU memory\n",
    "# Use patch-based method if x or y dimension is larger than max_size_gpu\n",
    "max_size_gpu = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ed592-b8f1-41f8-ae30-b5c8ab704b89",
   "metadata": {},
   "source": [
    "Count number of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "693f4242-3567-458b-a863-aff4d90db6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected models: 2\n",
      "Number of detected images: 2\n"
     ]
    }
   ],
   "source": [
    "valid_models = ['sfr_hrstem', 'sfr_lrstem', 'sfr_hrsem', 'sfr_lrsem', 'sfr_hrtem', 'sfr_lrtem']\n",
    "N = 0\n",
    "N_models = 0\n",
    "for m in next(os.walk(denoise_dir))[1]:\n",
    "    if m in valid_models:\n",
    "        N_models += 1\n",
    "        files = glob.glob(denoise_dir+'\\\\'+m+'\\\\*.tif')\n",
    "        N += len(files)\n",
    "print(f'Number of detected models: {N_models}')\n",
    "print(f'Number of detected images: {N}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b093577-40e2-493f-98b9-6763f161b867",
   "metadata": {},
   "source": [
    "Proceed with batch denoising:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "408aeafd-32ab-4e3a-8e85-ca6fcc36e10b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising of 2 FEI/TFS TIFF images.\n",
      "########################\n",
      "Model: sfr_hrsem\n",
      "Loading network...\n",
      "Creation of the directory examples/tfs_fei_TIFF_denoise\\sfr_hrsem\\output failed. Probably already present.\n",
      "Denoising images...\n",
      "Image 1/2\n",
      "########################\n",
      "Model: sfr_lrsem\n",
      "Loading network...\n",
      "Creation of the directory examples/tfs_fei_TIFF_denoise\\sfr_lrsem\\output failed. Probably already present.\n",
      "Denoising images...\n",
      "Image 2/2\n",
      "Patch-based denoise...\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "########################\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "counter = 1\n",
    "\n",
    "print(f'Denoising of {N} FEI/TFS TIFF images.')\n",
    "print('########################')\n",
    "for m in next(os.walk(denoise_dir))[1]:\n",
    "    if m in valid_models:\n",
    "        # Load model\n",
    "        print(f'Model: {m}')\n",
    "        print('Loading network...')\n",
    "        r_em_nn = load_network(m)\n",
    "        \n",
    "        # Create folder for output files\n",
    "        outputpath = denoise_dir + '\\\\' + m + '\\\\output'\n",
    "        try: os.mkdir(outputpath)\n",
    "        except OSError: print(f'Creation of the directory {outputpath} failed. Probably already present.')\n",
    "        else: print(f'Successfully created the directory {outputpath}')\n",
    "        \n",
    "        # Detect and prepare image files\n",
    "        files = glob.glob(denoise_dir+'\\\\'+m+'\\\\*.tif')\n",
    "        print('Denoising images...')\n",
    "        for f in files:\n",
    "            print(f'Image {counter}/{N}')\n",
    "            \n",
    "            # For FEI images, metadata is stored in tif.fei_metadata\n",
    "            # Read out pixel size and cut-off value to remove data bar\n",
    "            with tifffile.TiffFile(f) as tif:\n",
    "                pixelsize = tif.fei_metadata['Scan']['PixelWidth'] * 1e6 # convert to micron\n",
    "                unit = 'um'\n",
    "                image_ResolutionY = tif.fei_metadata['Image']['ResolutionY']\n",
    "            \n",
    "            # Read data into numpy array\n",
    "            image = tifffile.imread(f)\n",
    "            # Crop FEI/TFS data bar from image\n",
    "            image = image[0:image_ResolutionY,:]\n",
    "            nx, ny = image.shape\n",
    "            image = np.expand_dims(image, axis=(0, -1))\n",
    "            \n",
    "            # Denoise\n",
    "            if nx > max_size_gpu or ny > max_size_gpu:\n",
    "                print('Patch-based denoise...')\n",
    "                denoised = r_em_nn.predict_patch_based(image, patch_size=int(max_size_gpu/2), stride=int(max_size_gpu/4), batch_size=2)\n",
    "            else:\n",
    "                denoised = r_em_nn.predict(image)\n",
    "\n",
    "            # Save as TIFF image (32-bit)\n",
    "            tifffile.imwrite(outputpath + '\\\\' + f.rsplit('.', maxsplit=1)[0].split('\\\\')[-1] + f'-denoise-{m}.tif', denoised, imagej=True,\n",
    "                            resolution=(1./pixelsize, 1./pixelsize),\n",
    "                            metadata={'unit': unit})\n",
    "            counter += 1\n",
    "            \n",
    "        print('########################')\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b03f37-7dc1-4dcc-b1b9-224607c59210",
   "metadata": {},
   "source": [
    "## 6 Electron-Microscopy Formats (ser/dm3), single image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ca75d-e984-4453-acaa-4b99c45ea78a",
   "metadata": {},
   "source": [
    "`RosettaSciIO` is a package to handle file reading of scientific file formats (https://hyperspy.org/rosettasciio/index.html).  \n",
    "`RosettaSciIO` will be split from `HyperSpy` v2.0. I installed it directly from git in the following way:\n",
    "```\n",
    "conda activate my_denoise_env\n",
    "```\n",
    "```\n",
    "conda install git\n",
    "```\n",
    "```\n",
    "pip install git+https://github.com/hyperspy/rosettasciio.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db3776-bffb-4b26-bc0a-91b7a027c388",
   "metadata": {},
   "source": [
    "Here, we demonstrate only how to use `RosettaSciIO` to get the image data into a **2D numpy array** and extract the **pixel size** information.  \n",
    "The rest is the same as for the workflows above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9a0b9b36-a6e5-4109-b12b-40beb2a0733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import desired file readers\n",
    "from rsciio import tia,digitalmicrograph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda30ded-bb24-43f2-bc15-f4d4775031e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load an `ser` image\n",
    "The image values must be present as a two-dimensional array for denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6cce60e7-933e-4fef-b6b5-2027b0c1a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image file\n",
    "image_file = r'examples/ser-dm3/REBCO_1.ser'\n",
    "\n",
    "# Choose denoising model\n",
    "net_name = 'sfr_hrstem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "734a9ea7-0fb9-4a77-885f-7f663d2b6de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file contains image data and metadata\n",
    "file = tia.file_reader(image_file)\n",
    "\n",
    "# Inspect all content by uncommenting #file\n",
    "#file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "196c5eb1-c227-4927-a8d0-ee56b69fbd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:\t(2048, 2048)\n",
      "Data type:\tuint16\n"
     ]
    }
   ],
   "source": [
    "# Grab image data from file into a numpy array\n",
    "image = file[0]['data'] \n",
    "print(f'Image shape:\\t{image.shape}')\n",
    "print(f'Data type:\\t{image.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfac68d-eb99-46ab-a39b-657dd0a735a7",
   "metadata": {},
   "source": [
    "#### ... Insert single-image denoising workflow from above ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b88dbb-5cea-4eb2-bc4a-93733b1608c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "For saving a scaled TIFF, we can get the physical pixel size from the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a3a037cc-fa64-4956-bec7-72dc99c53204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel size: 0.057631 nm\n"
     ]
    }
   ],
   "source": [
    "pixelsize = file[0]['axes'][0]['scale']\n",
    "unit = file[0]['axes'][0]['units'] \n",
    "print(f'Pixel size: {pixelsize:.6f} {unit}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aca19a-a2a5-4d60-9c24-76cb58ca3f13",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load a `dm3` image\n",
    "The image values must be present as a two-dimensional array for denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8c3f70d9-bb68-4b67-95a8-a96639ebed5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image file\n",
    "image_file = r'examples/ser-dm3/REBCO-ROI_raw.dm3'\n",
    "\n",
    "# Choose denoising model\n",
    "net_name = 'sfr_hrstem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "26e2aaf5-da50-404c-848b-68ee2fd8fa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file contains image data and metadata\n",
    "file = digitalmicrograph.file_reader(image_file)\n",
    "\n",
    "# Inspect all content by uncommenting #file\n",
    "#file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78e2b03b-40fb-48b9-9070-8ae28eeed048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:\t(128, 128)\n",
      "Data type:\tuint16\n"
     ]
    }
   ],
   "source": [
    "# Grab image data from file into a numpy array\n",
    "image = file[0]['data'] \n",
    "print(f'Image shape:\\t{image.shape}')\n",
    "print(f'Data type:\\t{image.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72e0e1-c62a-480a-a1b4-7382a1fddb07",
   "metadata": {},
   "source": [
    "#### ... Insert a denoising workflow from above ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0d52b6-135b-48cf-8136-df627d1e2ae2",
   "metadata": {},
   "source": [
    "For saving a scaled TIFF, we can get the physical pixel size from the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4c846353-c8be-479a-ba69-007b2ded627a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel size: 0.054082 nm\n"
     ]
    }
   ],
   "source": [
    "pixelsize = file[0]['axes'][0]['scale']\n",
    "unit = file[0]['axes'][0]['units'] \n",
    "print(f'Pixel size: {pixelsize:.6f} {unit}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "be9281b7-0324-4e50-bfc0-e1ceb24d1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as TIFF image (32-bit)\n",
    "tifffile.imwrite(image_file.rsplit('.', maxsplit=1)[0]+f'-denoise-{net_name}.tif', denoised, imagej=True, \n",
    "        resolution=(1./pixelsize, 1./pixelsize), \n",
    "        metadata={'unit': unit})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e1a50-9213-41ae-aeb0-750f24b31f8f",
   "metadata": {},
   "source": [
    "### Other formats?  \n",
    "Have a look at https://hyperspy.org/rosettasciio/supported_formats/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
